#include <torch/torch.h>
#include <torch/script.h>
#include "mat_mul.h"
#include <iostream>
#include "kernel.h"
#include <algorithm>
#include <iomanip>
#include <random>

namespace sparse_transformers {
namespace layers {
namespace kernels {
void generate_array(float* data, int len){
    for(int i=0;i<len;i++){
        data[i] = i%10000;
    }
}

//检查结果是否正确
template<class type>
bool check_value(type* A,type *B, int len_a, int len_b){
    if(len_a != len_b){
        return false;
    }
    std::cout<<setiosflags(std::ios::fixed);
    for(int i=0;i<len_a;i++){
        if(abs(A[i]-B[i])>1e-4){
            std::cout<<std::setprecision(2)<<i<<" "<<A[i]<<" "<<B[i]<<" "<<abs(A[i]-B[i])<<std::endl;
            return false;
        }
        // return false;
    }
    return true;
}

void print_tensor(float* data,int len1, int len2){
    for(int i=0;i<len1;i++){
        for(int j=0;j<len2;j++){
            std::cout<<data[i*len1+j]<<" ";
        }
        std::cout<<std::endl;
    }
}


void generate_select_index_v1(int block_num,int head_num,int select_len, std::vector<int> &select_array, std::vector<int> array){
    for(int i=0;i<block_num*head_num;i++){
        std::shuffle(array.begin(),array.end(),std::mt19937{ std::random_device{}()});
        std::vector<int> temp(array.begin(),array.begin()+select_len);
        select_array.insert(select_array.end(),temp.begin(),temp.end());
    }
}

void generate_select_index(int block_num,int head_num,int select_len, std::vector<std::vector<int>> &select_array, std::vector<int> array){
    for(int i=0;i<block_num;i++){
        for(int j =0;j<head_num;j++){
            std::shuffle(array.begin(),array.end(),std::mt19937{ std::random_device{}()});
            std::vector<int> temp(array.begin(),array.begin()+select_len);
            select_array.push_back(temp);
        }
    }
}


void select_K_and_V(int block_num,int head_size,std::vector<std::vector<int>> select_array, torch::Tensor k, torch::Tensor v, torch::Tensor& out_k, torch::Tensor& out_v){
    for(int i=0;i<block_num;i++){
        for(int j=0;j<head_size;j++){
            auto temp = k.index_select(0,torch::from_blob(select_array[i*head_size+j].data(),{11},torch::kInt32)).index_select(1,torch::tensor({j})).squeeze(1);
            out_k = torch::cat({out_k,temp},0);
            auto temp1 = v.index_select(0,torch::from_blob(select_array[i*head_size+j].data(),{11},torch::kInt32)).index_select(1,torch::tensor({j})).squeeze(1);
            out_v = torch::cat({out_v,temp1},0);
        }
    }
    return ;
}

void test_gemm(){
    int seq_len = 4096, d_num = 768;
    torch::Tensor query = torch::zeros({seq_len,d_num},torch::kFloat);
    torch::Tensor key =torch::zeros({seq_len,d_num},torch::kFloat);
    torch::Tensor value =torch::zeros({seq_len,d_num},torch::kFloat);
    torch::Tensor out = torch::zeros({seq_len,d_num},torch::kFloat).to(at::kCUDA);

    generate_array(reinterpret_cast<float*>(query.data_ptr()),seq_len*d_num);
    generate_array(reinterpret_cast<float*>(key.data_ptr()),seq_len*d_num);
    generate_array(reinterpret_cast<float*>(value.data_ptr()),seq_len*d_num);


    int block_size = 64,head_num =12;
    int block_num = seq_len/block_size;
    int head_size = d_num / head_num;

    // for(int i =0;i<128;i++){
    //     std::cout<<reinterpret_cast<float*>(query.data_ptr())[i]<<" ";
    // }
    // std::cout<<std::endl;


    // query = query.view({block_num,block_size,head_num,d_num/head_num});
    // query = query.permute({2,0,1,3}).contiguous();

    // for(int i =0;i<128;i++){
    //     std::cout<<reinterpret_cast<float*>(query.data_ptr())[i]<<" ";
    // }
    // std::cout<<std::endl;


    query = query.reshape({block_num,head_num,block_size,d_num/head_num}).to(at::kCUDA);
    key = key.reshape({block_num,head_num,block_size,d_num/head_num}).to(at::kCUDA);
    value = value.reshape({block_num,head_num,block_size,d_num/head_num}).to(at::kCUDA);
    
    std::vector<int> ivec(block_num);
    std::iota(ivec.begin(), ivec.end(), 0);
    int select_len = 11;
    std::vector<int> select_index1 = {54,9,15,21,19,26,29,62,30,39,44,0,34,52,46,3,45,10,61,14,54,56,25,52,45,32,55,23,38,57,17,44,19,46,35,36,27,42,1,32,24,7,50,38,56,29,25,21,18,5,3,31,26,59,16,2,17,57,39,3,6,46,51,40,18,16,1,55,12,30,36,50,52,57,8,7,5,22,40,7,49,62,48,59,0,44,41,38,38,28,56,37,22,62,55,30,11,51,36,27,32,16,56,57,12,44,11,36,23,54,17,62,48,36,22,28,20,34,42,32,39,29,31,34,51,5,14,11,26,36,28,30,41,43,2,7,11,33,19,44,18,50,37,51,0,4,40,26,38,46,20,49,22,29,55,24,41,60,26,10,15,57,59,9,48,26,19,29,13,16,62,25,61,11,36,32,30,4,63,21,58,31,53,27,50,25,40,54,8,29,37,26,36,14,52,11,9,43,31,16,50,53,3,41,49,62,45,25,12,52,21,4,22,17,63,7,53,48,8,23,37,19,21,35,61,0,42,24,62,23,46,20,26,49,2,9,21,43,13,7,1,34,51,5,40,21,27,52,55,32,10,16,2,30,31,15,57,55,27,59,32,8,20,43,54,55,26,16,31,45,24,8,1,43,44,19,41,58,37,34,54,51,60,28,42,21,15,14,4,7,40,36,26,25,6,60,51,19,48,23,56,10,36,16,44,11,52,55,36,30,16,51,57,35,7,37,4,20,49,13,33,0,63,22,14,47,36,54,59,43,55,63,42,25,8,45,19,48,56,43,47,35,16,49,23,58,2,56,1,24,38,21,41,33,63,39,36,52,42,35,46,55,37,49,7,14,47,0,52,42,4,34,36,2,53,12,51,11,19,32,56,6,21,24,50,8,61,44,34,5,29,38,23,12,30,37,17,22,16,62,33,0,44,56,59,54,25,10,38,60,42,3,1,33,48,54,6,29,39,26,54,61,19,18,28,46,56,43,60,63,24,54,47,18,62,6,61,2,29,43,14,61,53,2,36,22,41,16,35,4,57,54,47,44,46,59,60,35,6,15,51,1,46,28,1,58,21,38,27,36,47,56,16,31,12,40,57,50,9,47,51,4,2,1,38,62,52,9,4,8,48,14,17,27,18,52,58,3,32,12,13,47,62,43,2,34,40,10,57,8,27,11,0,50,28,32,2,44,16,6,46,30,61,4,21,26,29,31,11,32,42,49,23,36,14,50,40,38,46,24,47,63,7,35,25,29,39,57,45,16,16,1,47,23,14,9,54,40,38,15,20,63,36,46,21,2,45,42,38,24,33,47,38,1,9,50,27,29,26,39,63,22,14,56,0,58,40,29,32,2,18,3,39,41,50,52,28,30,6,13,29,55,21,8,31,50,47,63,26,51,45,21,25,43,61,6,6,20,31,61,11,35,26,62,50,60,27,17,0,14,27,22,37,52,24,11,40,13,45,28,9,57,30,63,17,48,31,15,6,47,33,12,42,5,23,35,34,15,38,2,26,14,15,42,27,56,63,36,23,25,61,31,33,42,22,29,55,23,4,26,3,25,17,51,9,50,42,54,29,24,60,30,5,35,24,38,14,22,50,46,15,21,23,11,37,46,12,28,0,2,4,41,10,50,16,16,48,4,7,51,43,32,42,27,49,1,44,33,52,11,55,24,49,60,27,48,25,11,7,55,57,15,0,13,60,37,21,54,53,58,9,47,61,16,32,57,43,38,11,15,56,40,34,21,42,2,27,31,57,22,51,21,55,54,56,57,47,46,45,12,5,21,43,22,10,2,46,57,50,13,24,34,51,0,22,35,3,49,45,60,10,57,33,43,41,57,1,46,47,6,40,62,52,63,50,7,43,37,46,55,36,29,23,60,39,33,57,30,41,16,63,21,34,12,53,14,40,43,53,59,63,35,56,27,61,60,25,17,19,37,63,9,14,60,21,8,23,3,49,25,60,41,20,50,13,12,40,38,28,30,44,12,41,19,51,34,62,4,35,13,4,17,12,44,8,19,20,37,18,57,45,33,5,22,57,16,2,0,50,59,13,19,0,62,1,20,13,36,17,34,38,26,10,22,26,4,36,27,59,18,16,56,37,34,18,20,60,8,16,58,34,46,17,27,2,42,15,40,54,63,26,10,39,20,29,44,13,31,34,61,3,54,38,14,55,11,9,56,40,60,47,18,39,43,0,12,55,33,48,47,60,54,57,7,2,37,58,50,30,2,39,52,46,55,4,53,62,6,30,35,2,35,26,19,29,33,38,27,51,34,24,34,44,62,14,28,30,38,17,26,35,42,62,44,35,4,43,59,29,28,2,48,30,9,21,25,6,17,29,34,0,46,39,47,52,30,60,53,49,39,5,27,38,22,42,47,3,21,46,58,17,59,14,12,16,1,59,53,52,7,18,49,39,43,19,12,48,61,32,0,45,25,37,60,59,28,21,40,42,44,47,10,18,48,63,11,24,54,62,43,9,33,59,49,14,10,34,36,42,62,23,28,38,57,10,20,24,54,11,0,35,53,44,0,47,20,45,10,29,17,33,22,35,31,34,21,29,37,32,15,36,47,3,40,42,50,23,47,19,18,9,3,58,34,54,48,31,7,42,6,43,16,24,15,49,31,51,60,39,52,23,29,13,58,26,19,19,57,49,9,47,56,6,18,32,1,43,26,31,47,9,13,14,23,55,5,37,43,19,34,24,11,17,9,41,59,49,28,0,36,53,52,58,7,44,38,10,20,51,25,6,54,2,61,59,48,46,13,49,5,26,42,49,21,12,14,27,13,7,63,38,53,49,32,13,42,5,33,26,6,41,18,61,36,48,13,21,34,46,30,10,47,40,18,27,7,44,43,25,54,20,35,62,30,10,49,27,35,4,9,2,61,13,62,19,20,48,53,11,20,60,13,45,22,46,50,28,24,28,57,56,4,58,7,51,61,37,20,21,60,52,7,27,3,10,0,8,53,59,63,13,3,21,14,52,34,48,57,0,54,21,15,24,55,6,58,30,51,34,60,27,32,59,23,34,6,37,17,39,11,26,13,3,37,57,51,21,24,11,63,56,53,16,1,27,24,3,53,51,7,34,11,60,44,1,41,43,16,55,53,15,7,30,51,38,11,19,57,5,2,44,53,12,63,41,52,26,7,40,19,54,48,36,13,45,44,42,16,51,17,1,49,15,55,37,26,62,54,25,58,51,61,8,21,52,62,45,56,6,52,59,26,10,25,54,14,43,7,44,57,11,44,54,53,60,41,59,13,37,34,58,61,59,9,63,48,29,22,31,1,37,54,29,33,26,30,43,46,10,2,57,1,28,63,33,4,36,34,58,14,35,59,62,8,5,2,16,44,7,28,54,21,45,48,61,50,22,30,41,52,55,27,37,48,29,46,11,47,10,45,30,38,21,43,60,36,52,54,10,60,15,61,63,35,46,13,48,43,40,22,38,32,4,46,11,5,21,54,37,8,16,27,46,45,9,42,51,44,17,5,51,7,5,54,27,13,36,43,44,30,3,41,10,5,35,38,37,26,0,3,57,51,59,6,33,0,35,13,25,47,28,56,16,47,29,49,24,30,1,23,55,19,21,44,57,53,21,3,43,48,34,56,55,54,37,25,11,13,0,9,31,63,38,61,5,27,6,61,51,11,44,54,48,53,52,3,7,58,8,57,56,50,59,34,27,20,9,60,6,15,33,12,20,63,40,10,0,52,21,14,24,46,8,13,3,59,32,49,57,29,55,16,27,10,6,52,7,24,23,44,41,8,55,34,15,13,28,36,58,38,27,1,4,10,47,46,54,31,16,61,35,50,0,57,9,61,60,49,43,2,11,34,18,15,27,24,60,13,59,12,17,52,22,29,5,53,29,1,34,61,0,27,28,12,20,60,35,9,24,42,15,55,13,1,3,41,20,60,20,45,35,7,34,58,31,62,32,57,33,32,22,46,63,53,3,50,56,60,61,62,14,18,33,19,53,42,11,23,20,2,42,14,40,32,18,26,45,16,60,6,10,14,0,6,21,7,54,55,26,18,34,58,22,8,61,10,17,38,5,16,9,62,56,40,27,43,53,47,60,22,19,33,29,55,7,39,19,47,20,29,26,41,32,63,27,59,39,58,26,56,61,30,48,47,11,34,17,7,5,13,53,37,10,19,55,58,18,30,22,20,38,39,37,31,52,60,6,19,31,42,14,33,32,46,4,15,2,1,54,9,28,45,39,31,1,58,13,14,47,53,30,38,8,34,23,57,25,19,62,61,43,8,62,60,3,14,35,2,11,43,41,7,60,11,26,44,38,43,19,29,4,16,0,25,29,16,5,34,45,36,42,28,63,49,7,27,53,21,61,45,59,31,34,55,22,36,27,15,47,19,9,34,12,20,7,11,39,50,23,11,4,1,47,43,10,18,34,1,12,63,13,18,39,26,9,54,47,17,55,6,56,31,26,40,43,9,21,39,1,42,10,48,53,54,34,37,51,52,22,11,41,16,14,10,35,9,3,39,12,42,40,53,0,9,2,10,6,62,19,16,14,17,54,60,53,11,9,39,0,6,19,16,8,7,50,38,28,17,57,55,63,3,52,24,4,38,15,45,26,16,61,60,48,20,13,48,1,62,43,7,61,35,23,36,53,14,17,36,12,60,40,18,6,11,48,37,35,6,29,33,9,31,42,60,61,44,7,38,14,23,62,1,27,37,40,34,3,9,58,1,2,40,18,46,20,54,5,21,34,44,52,13,9,53,19,16,22,57,12,26,49,44,58,27,59,49,52,55,63,47,31,53,29,28,32,15,51,2,22,37,8,7,62,62,29,47,24,35,27,58,55,33,2,51,61,51,26,53,4,3,52,44,47,42,5,5,43,9,8,48,62,13,26,41,46,42,15,0,51,25,18,22,33,29,37,17,36,35,0,58,14,23,16,45,39,8,60,11,3,2,39,11,45,48,36,50,35,13,44,7,21,56,4,45,37,42,15,51,62,20,42,62,28,57,40,38,27,61,29,33,41,62,56,8,29,50,33,3,16,27,36,40,5,41,28,34,8,9,15,24,16,44,31,12,58,43,61,21,0,25,20,33,45,37,61,6,49,1,11,30,44,37,58,36,57,32,33,0,2,23,31,49,62,41,24,25,32,28,9,7,15,37,5,4,43,6,57,1,42,3,51,27,58,62,25,20,34,57,22,46,58,12,59,38,33,10,9,47,51,49,5,41,13,43,18,58,34,7,26,17,58,52,13,9,22,18,35,54,3,40,27,45,8,60,46,43,39,34,56,37,18,32,7,45,38,23,1,42,31,49,2,24,44,8,54,18,27,44,30,34,40,21,52,43,42,44,2,55,9,50,23,15,52,13,57,47,35,7,10,30,58,1,27,31,37,54,49,62,55,8,39,52,35,47,58,16,23,39,46,4,40,35,29,51,9,61,57,3,63,2,51,17,35,8,7,46,33,57,25,38,28,5,17,8,59,29,21,46,11,35,21,32,63,16,50,11,4,49,55,62,41,0,55,45,28,23,22,24,36,57,59,35,59,16,7,13,6,21,46,26,20,45,44,23,50,51,13,26,46,37,63,29,16,38,54,12,24,17,5,22,10,9,0,56,60,14,28,48,18,35,22,8,9,43,44,5,43,12,51,39,16,36,61,7,33,38,63,22,43,52,28,1,45,50,60,9,37,20,46,37,10,57,8,31,61,19,52,59,9,25,18,1,43,37,44,38,45,12,40,29,32,29,54,27,59,41,33,47,4,5,12,10,61,42,17,25,29,12,43,60,53,4,12,23,35,37,9,27,30,11,25,7,59,12,8,20,46,9,22,43,48,42,51,32,30,8,45,54,26,33,27,48,40,25,53,48,43,27,13,23,44,12,17,45,32,0,44,38,32,20,17,31,46,57,55,23,60,9,7,42,45,14,62,46,16,38,19,3,23,42,46,22,6,49,26,45,35,40,43,41,1,49,52,55,53,61,35,30,19,43,37,36,42,23,19,34,10,40,51,2,27,42,62,2,9,47,10,63,13,34,0,51,41,21,3,26,40,24,16,55,6,49,31,4,6,14,56,23,10,3,63,19,60,25,39,57,5,19,47,29,34,8,60,13,50,54,56,36,13,28,15,41,16,50,0,2,21,48,9,41,32,37,51,19,43,23,40,45,2,47,8,26,42,35,3,57,41,36,46,28,61,62,59,22,47,14,11,5,29,43,61,29,25,19,41,40,45,14,2,53,51,22,43,25,19,5,31,3,6,23,21,12,63,39,47,27,50,3,43,53,5,6,40,44,57,8,60,10,50,24,34,3,5,3,18,48,55,12,51,8,45,63,29,2,3,39,51,37,60,44,63,31,7,34,20,9,59,42,27,56,16,6,11,35,24,29,16,31,62,54,0,24,59,43,45,63,21,29,6,53,34,2,26,60,30,20,32,5,11,42,60,20,23,30,31,46,37,48,12,40,10,51,59,1,9,57,27,12,23,28,6,42,12,16,9,45,19,29,35,43,36,19,53,2,6,7,56,42,48,63,5,16,59,8,55,5,3,21,13,54,38,46,58,12,7,31,38,21,4,24,18,57,48,49,39,0,27,20,11,6,50,23,8,53,63,60,62,43,10,31,32,4,30,2,11,59,14,34,31,8,6,21,22,23,26,13,62,12,24,62,54,11,44,35,33,60,37,23,24,36,4,3,28,1,22,46,32,61,18,2,10,12,4,51,0,11,25,59,17,55,18,41,21,26,44,35,25,3,20,40,54,54,50,59,12,5,23,0,61,44,26,56,28,43,42,35,13,27,56,61,15,31,22,1,8,51,39,58,43,21,24,31,11,48,13,61,12,16,41,50,58,26,63,3,21,52,42,31,44,9,16,29,55,11,0,1,57,51,13,5,10,35,18,33,12,50,22,35,26,62,59,38,16,5,33,39,44,43,21,53,52,7,3,58,12,61,59,20,50,33,44,12,36,51,56,42,34,31,27,0,52,23,16,47,8,0,13,22,51,4,21,57,6,50,59,30,33,2,63,18,42,35,51,34,2,61,17,62,9,63,26,18,27,51,55,21,12,62,61,59,34,53,2,42,33,16,22,11,3,38,36,49,25,53,14,41,6,63,49,27,52,2,62,58,0,9,26,7,29,46,0,14,35,42,43,38,47,8,21,38,36,18,33,55,61,49,23,0,58,7,3,38,50,63,44,2,10,52,36,25,22,58,46,14,13,5,29,62,63,20,15,19,59,12,48,42,55,17,32,27,25,37,52,14,57,3,11,45,6,59,5,33,26,1,3,43,17,30,10,58,6,53,12,11,46,3,32,24,34,31,28,63,29,13,50,1,37,31,38,48,34,32,28,2,24,23,27,46,5,9,11,58,1,61,34,26,63,34,20,39,55,26,16,25,23,31,18,4,58,27,49,47,0,13,1,18,9,26,48,25,24,11,3,30,29,4,6,52,22,49,56,6,58,46,17,59,35,15,7,43,58,22,12,48,40,10,35,50,32,8,2,8,63,32,42,10,3,55,22,58,36,44,24,11,38,19,61,49,52,5,41,27,53,57,24,29,63,54,38,62,50,47,27,25,15,58,42,27,28,21,33,22,17,44,16,49,8,18,35,32,50,21,10,60,15,20,62,61,35,3,20,12,26,52,9,24,21,50,20,47,63,60,46,37,22,19,27,12,35,18,31,48,38,8,46,37,14,0,19,39,44,24,8,32,22,43,58,38,51,4,47,30,22,4,20,27,26,44,34,3,62,22,52,57,25,49,62,56,16,37,30,41,2,19,42,41,61,9,22,59,50,6,23,24,20,62,38,52,54,50,12,13,36,37,25,1,0,14,4,32,10,44,59,48,63,47,0,44,36,3,41,62,11,5,40,37,2,43,31,46,5,28,1,39,14,3,41,50,16,58,60,10,46,48,41,57,33,36,44,34,48,8,6,54,63,3,2,62,17,56,42,26,4,16,20,28,57,35,14,36,33,58,9,18,40,10,4,28,29,36,13,38,20,15,22,60,37,34,57,58,5,3,7,48,54,55,8,22,27,12,2,43,14,26,14,3,37,52,29,40,7,9,28,10,10,23,2,45,12,1,43,31,13,24,19,35,26,42,29,52,43,63,10,24,37,2,25,21,48,23,12,0,46,26,56,40,20,63,56,0,48,6,57,34,60,58,7,42,63,9,7,37,59,5,14,3,51,1,42,3,34,19,10,22,20,15,0,29,7,5,6,9,59,12,60,27,61,36,15,1,40,56,7,9,14,32,3,35,27,28,45,47,15,51,17,14,27,30,20,54,50,18,25,54,57,7,36,50,44,46,29,22,38,17,59,27,56,52,54,21,11,43,48,35,51,9,52,31,57,30,19,49,61,50,26,8,24,23,41,35,63,26,39,49,3,1,6,12,48,23,35,10,18,56,63,9,31,32,30,9,55,13,35,5,31,53,10,2,25,33,32,51,17,4,53,13,48,36,2,12,50,29,36,63,27,3,2,6,51,61,5,60,49,1,33,36,57,34,14,12,0,40,9,29,41,40,17,20,45,13,34,19,62,27,8,17,15,13,23,24,41,42,7,60,41,2,0,4,27,22,7,6,34,42,24,12,28,49,44,3,4,33,30,42,41,50,27,13,10,56,2,49,8,58,59,63,7,33,45,59,14,29,60,49,55,16,38,53,8,13,63,7,16,41,43,22,31,0,21,18,13,63,52,30,17,49,58,16,1,34,15,12,28,63,23,11,10,57,36,30,6,55,51,1,56,61,58,46,6,31,62,22,59,15,54,52,5,23,19,27,22,63,37,54,25,15,24,52,53,55,17,30,48,51,0,55,16,52,4,53,58,23,8,44,3,44,21,34,25,58,26,8,2,9,41,31,13,42,59,9,5,50,12,39,0,61,30,61,12,45,11,0,43,54,14,53,46,49,25,32,17,0,45,49,8,44,41,38,7,58,51,42,28,5,4,41,22,27,23,44,37,16,33,51,39,35,40,52,17,12,20,44,10,41,2,39,53,9,15,16,27,20,58,25,7,19,23,47,54,51,0,48,15,0,33,38,51,48,17,7,22,50,11,62,22,20,52,48,1,29,18,45,33,28,25,20,8,29,11,17,18,3,34,61,55,40,46,15,31,7,38,48,41,0,42,43,57,3,35,43,9,61,39,22,40,54,12,55,26,10,28,30,40,46,24,6,11,42,47,20,4,46,12,10,55,34,21,60,63,7,9,47,22,28,2,12,23,0,8,38,54,51,11,48,34,39,60,56,35,26,27,13,38,23,52,51,20,8,11,31,41,0,7,32,1,0,58,51,47,49,4,54,27,2,29,22,11,52,39,40,7,45,35,18,21,27,63,30,45,54,55,61,44,33,1,51,6,37,56,49,13,58,54,51,45,9,8,53,46,57,48,36,25,44,54,29,4,23,17,19,24,35,36,37,27,28,8,55,53,33,29,3,8,17,1,2,14,57,11,24,32,35,33,12,1,27,0,62,36,15,59,41,50,47,43,16,22,57,20,19,62,21,21,9,59,61,13,58,53,39,41,31,34,50,40,49,14,26,56,52,11,58,63,61,61,42,53,51,37,45,31,39,35,3,58,34,14,56,19,6,9,8,35,2,31,40,58,29,60,31,40,47,9,49,30,37,52,3,19,26,33,58,5,9,47,45,39,51,9,26,11,30,29,57,51,27,15,63,18,21,38,41,57,32,40,60,17,22,5,49,51,62,56,27,39,24,54,21,42,4,29,19,45,1,37,56,17,22,24,63,30,10,38,31,23,26,25,44,6,45,35,51,17,60,8,59,54,42,30,14,45,6,11,41,16,25,21,31,4,13,47,5,26,37,2,12,35,52,46,19,48,34,32,54,17,25,27,50,30,11,18,5,52,20,25,15,26,28,4,11,50,40,62,34,55,17,53,37,34,16,39,36,40,10,54,43,52,59,58,59,17,8,46,2,31,37,9,5,20,52,10,42,57,46,47,9,20,31,24,23,16,48,2,17,33,27,50,26,5,29,14,63,47,51,28,2,4,54,21,63,57,5,29,26,15,40,31,52,27,24,33,59,20,30,7,8,12,49,9,19,35,60,31,43,30,39,29,62,41,0,57,40,23,45,7,48,18,38,17,53,12,21,43,13,41,19,31,48,2,8,50,12,34,5,33,1,17,40,8,52,61,25,37,19,24,38,33,23,53,55,28,25,31,36,39,19,37,58,22,42,22,44,25,6,58,45,17,8,12,51,53,30,9,25,5,17,40,1,47,38,24,21,22,8,24,32,41,12,26,2,38,6,61,40,57,59,22,29,49,62,16,44,46,18,42,16,17,22,46,25,55,32,10,49,53,45,40,63,55,30,18,24,62,39,46,14,24,18,3,54,0,14,45,49,44,19,51,27,63,54,41,3,11,13,9,30,58,46,9,10,2,0,60,28,46,51,26,38,43,33,0,53,5,48,2,32,41,61,26,63,35,52,48,50,12,25,18,10,43,59,33,27,55,52,44,4,36,39,26,33,16,32,36,0,9,58,35,45,37,25,48,47,21,19,38,26,61,58,17,60,7,31,37,54,28,3,40,25,9,29,48,52,33,1,44,30,60,13,21,20,2,31,3,57,22,18,55,60,39,47,44,43,13,18,26,52,57,30,56,17,48,32,22,47,27,44,33,45,34,10,60,11,13,6,2,8,26,48,38,30,58,24,23,5,2,50,17,9,43,45,16,18,6,29,4,0,13,24,15,3,49,3,14,62,9,37,52,18,38,34,8,49,14,30,62,53,34,54,38,41,35,50,10,18,53,31,5,9,52,62,58,30,50,29,39,61,51,23,54,58,44,52,24,8,37,8,35,2,23,62,57,7,21,37,32,47,39,60,10,46,40,19,2,6,61,20,55,7,5,36,22,35,55,50,24,43,49,31,38,19,51,13,31,8,57,10,30,55,11,50,33,24,31,18,36,61,63,4,42,55,39,61,14,35,25,45,54,60,6,4,59,63,9,16,32,31,45,51,55,53,33,18,36,15,29,14,24,38,1,3,57,34,21,40,37,25,11,29,48,55,24,30,17,33,58,24,13,25,1,10,50,36,4,42,18,53,42,6,32,48,3,44,8,7,35,58,19,32,31,60,26,53,1,30,46,52,40,33,28,6,7,57,31,47,11,24,39,53,16,54,19,33,42,60,24,30,28,23,43,37,33,21,36,61,62,34,40,52,32,56,10,63,35,15,61,44,5,37,36,31,47,30,44,33,12,36,41,1,42,31,14,56,58,38,0,36,21,37,9,39,46,41,25,45,3,57,16,36,26,13,38,52,59,19,12,58,57,46,39,62,5,23,35,22,36,7,28,29,57,31,12,52,2,20,42,48,37,3,33,18,4,1,60,62,57,12,28,28,29,35,32,43,19,50,34,17,51,20,26,34,44,35,9,46,41,54,27,4,56,30,9,48,1,12,55,51,6,49,42,47,19,63,47,44,21,53,57,36,38,56,52,50,19,33,48,21,51,37,16,28,18,44,4,35,27,53,36,39,10,8,45,33,21,0,54,59,34,23,11,3,20,42,9,26,16,53,15,2,23,50,26,47,9,58,17,52,9,19,16,20,51,30,35,48,13,10,55,32,0,37,23,61,1,52,12,59,7,38,36,34,37,2,33,41,17,13,42,5,32,52,41,34,29,44,43,37,63,18,51,18,57,24,8,48,50,29,2,31,41,1,8,6,43,47,16,27,53,38,17,0,5,63,43,57,36,61,10,1,32,5,25,51,55,62,18,50,33,25,38,10,42,49,56,41,0,56,18,58,38,63,2,57,39,36,14,55,10,30,18,63,6,29,41,15,50,7,33,25,6,52,28,49,2,3,36,23,23,42,29,7,37,61,18,16,45,57,46,27,49,6,48,16,34,53,12,29,22,30,42,15,24,6,27,58,5,29,56,1,26,55,16,53,8,11,50,10,49,47,43,17,62,21,15,54,6,0,26,11,16,27,24,27,49,48,45,53,46,31,38,3,40,47,34,22,60,21,51,52,13,58,11,19,30,33,7,12,45,37,26,34,59,43,22,3,57,59,58,1,23,16,39,27,53,21,35,2,32,3,36,17,19,1,54,4,31,62,52,20,15,57,10,55,48,29,42,62,17,49,3,0,59,26,19,24,13,53,55,46,28,56,47,8,23,34,38,45,19,27,44,37,2,5,23,44,20,8,35,0,27,61,54,55,21,42,46,30,18,0,2,17,24,32,22,19,21,33,0,4,16,56,3,9,44,28,1,30,26,57,22,61,63,42,51,18,12,17,10,45,26,49,40,43,31,46,44,57,47,54,41,0,59,58,50,21,7,4,52,55,29,58,53,34,48,23,39,36,37,10,3,52,33,28,39,8,21,19,40,24,51,23,2,5,26,33,44,6,31,46,40,48,36,10,45,50,63,4,29,52,25,62,2,36,23,32,16,14,1,52,45,35,9,49,7,34,51,43,60,38,58,1,41,33,19,63,4,57,37,5,8,48,27,42,22,23,61,55,24,0,57,34,40,13,35,56,61,45,7,52,18,40,42,22,36,25,58,6,48,61,5,16,7,22,37,38,46,2,26,47,14,34,22,18,32,35,49,11,52,30,27,2,17,62,22,4,12,45,7,32,45,59,0,49,8,47,22,2,38,62,37,6,20,61,27,7,35,41,62,57,32,55,35,39,37,38,29,41,60,9,23,24,50,2,39,33,57,10,53,59,37,12,7,25,48,39,13,45,31,1,17,24,58,18,61,59,15,26,14,25,9,53,28,7,6,25,31,46,49,8,62,37,34,63,51,11,6,21,25,48,24,0,23,20,43,19,27,1,8,60,6,25,45,12,27,38,35,62,25,41,2,47,13,3,50,46,24,34,44,56,50,23,8,5,0,34,30,52,63,3,47,62,29,28,34,10,1,37,43,9,63,53,6,31,19,7,46,34,17,52,35,27,9,14,16,55,24,0,31,11,53,57,41,9,63,43,13,48,57,24,22,25,18,37,1,42,16,10,26,23,4,36,61,51,5,16,38,49,60,8,0,1,28,45,44,37,39,32,41,10,52,19,23,59,25,44,31,6,38,58,26,18,24,33,2,56,31,50,10,16,34,39,53,59,21,52,35,51,29,23,16,43,32,47,6,26,59,63,8,3,51,27,47,15,55,10,19,30,43,53,46,42,26,40,9,36,11,37,55,25,3,1,5,6,41,51,34,50,19,63,54,26,45,27,29,18,32,52,41,20,30,48,26,22,56,10,19,1,54,61,55,40,52,39,50,54,21,14,2,55,19,6,17,33,27,45,2,46,63,36,37,4,58,24,19,28,52,52,31,24,34,44,2,10,43,8,60,23,23,20,31,5,62,39,48,29,61,10,8,41,48,1,24,61,56,2,13,19,32,52,45,34,58,36,9,5,12,44,61,49,20,41,49,28,13,19,5,57,45,22,43,46,54,62,17,30,37,14,23,11,41,47,60,35,39,1,41,36,2,55,10,12,6,25,35,21,48,20,43,53,14,31,41,47,29,23,32,43,52,26,44,7,9,28,39,0,8,53,41,38,54,9,33,45,24,15,26,40,10,11,16,33,12,26,52,60,24,7,49,42,27,5,13,51,4,8,50,19,47,49,12,43,30,17,34,45,2,59,55,63,0,2,50,20,18,8,1,40,32,14,58,47,37,55,24,63,43,9,44,50,58,61,17,6,42,18,0,24,47,52,51,50,40,14,34,30,44,55,52,36,1,16,7,26,21,58,15,0,49,7,12,53,3,22,62,0,40,34,26,25,41,8,62,43,24,39,45,31,60,58,30,12,7,48,49,61,32,23,39,31,32,22,18,5,50,8,45,37,33,60,40,14,18,46,23,5,45,7,52,51,32,54,1,40,12,50,17,43,24,37,24,19,18,49,62,7,11,43,15,59,6,63,26,31,47,58,18,30,60,8,11,20,40,21,32,12,49,61,54,37,30,39,47,5,47,24,37,34,7,28,29,30,52,60,9,39,28,19,1,16,15,51,40,54,20,9,2,39,59,55,62,38,3,19,48,0,31,59,41,62,12,37,23,35,33,8,50,61,32,54,27,16,47,28,51,11,40,31,43,22,57,63,56,27,40,45,52,46,44,40,13,61,26,54,34,29,38,60,36,43,10,14,48,45,19,13,18,35,15,32,50,20,4,17,45,43,49,14,7,12,11,37,15,16,10,12,44,47,20,19,59,32,11,54,16,45,14,63,24,23,36,30,7,62,40,47,17,5,62,55,0,54,1,10,57,20,58,36,6,17,10,59,47,62,7,42,32,26,54,52,46,56,49,5,2,44,61,37,45,52,50,49,26,63,55,15,41,11,50,33,23,24,32,18,11,39,40,31,62,37,46,32,14,16,48,55,38,22,18,17,0,54,38,32,7,19,53,55,44,11,29,58,11,8,50,37,40,36,13,62,39,53,46,20,45,52,12,28,43,32,62,16,56,5,12,39,14,63,31,60,48,2,53,24,49,31,36,4,53,30,6,58,55,62,63,18,52,42,15,20,22,50,5,33,55,10,30,26,27,7,41,62,40,5,63,53,15,37,3,48,31,52,21,51,58,0,49,1,3,20,50,45,49,11,9,33,31,2,59,0,57,48,40,8,1,52,46,41,25,10,28,17,34,15,36,51,39,16,12,5,26,31,20,2,50,3,34,17,23,60,22,42,56,9,14,0,43,25,33,51,48,27,16,36,37,9,0,26,41,28,49,61,60,59,40,36,60,32,10,56,11,13,39,57,12,9,35,51,55,17,52,28,4,43,6,38,33,18,20,37,22,46,28,4,3,56,59,21,38,39,0,25,52,62,19,54,57,10,56,58,52,43,19,35,62,46,7,10,36,49,2,9,25,33,54,0,21,20,4,29,60,0,55,62,50,13,17,18,6,38,49,36,35,55,26,48,53,27,39,15,44,57,19,22,2,37,9,17,6,41,62,21,32,25,36,50,4,40,58,0,7,62,35,33,27,6,8,18,57,44,47,61,38,30,10,33,5,7,58,39,6,36,21,62,22,0,2,26,52,40,59,46,41,63,33,53,49,16,3,2,12,40,46,33,24,11,37,27,42,27,13,4,46,16,30,28,49,22,15,62,0,50,11,15,19,60,53,49,16,21,45,8,55,38,54,51,13,32,31,53,29,17,45,38,36,49,5,16,26,28,7,13,26,54,22,23,40,14,27,25,60,35,34,34,7,17,11,35,33,10,8,40,48,20,39,38,14,52,5,13,43,62,42,49,37,55,9,61,37,19,8,17,47,51,24,38,2,45,30,39,17,11,21,1,41,28,35,22,26,16,1,52,30,55,8,13,60,57,36,7,38,61,12,43,51,15,5,37,60,12,23,13,33,29,55,61,46,14,60,30,27,20,40,34,7,54,32,3,43,12,47,32,11,58,33,0,39,31,25,47,62,24,34,55,24,3,49,56,31,30,29,12,26,39,24,45,33,7,44,15,55,19,48,11,14,63,12,16,60,47,11,4,41,53,17,58,56,14,36,5,45,37,22,17,59,15,30,42,19,28,21,36,37,41,39,4,54,26,30,6,18,10,8,36,29,19,7,58,8,4,21,37,15,11,50,40,38,1,14,23,22,5,52,10,29,26,0,39,30,19,11,53,36,38,47,63,29,26,61,20,18,43,48,53,55,0,12,3,47,2,52,40,4,56,10,6,53,37,15,25,44,42,52,49,8,18,62,46,22,11,31,43,34,14,62,46,29,36,16,1,48,10,6,7,13,37,48,4,57,0,18,55,56,42,12,9,17,63,18,42,20,16,38,7,47,51,52,33,12,52,53,15,48,23,8,0,28,63,51,35,4,38,25,27,49,60,13,52,5,14,25,61,30,4,1,37,8,6,5,51,25,4,55,2,20,34,11,30,0,18,16,20,16,48,21,0,32,31,39,47,59,12,42,24,1,2,60,19,36,63,5,25,27,32,43,52,50,7,30,21,8,5,63,49,44,33,61,12,53,49,39,47,57,22,1,41,9,63,27,50,57,44,56,15,55,32,58,49,30,21,36,8,18,26,57,44,37,19,21,29,36,41,49,56,20,1,55,47,57,61,21,52,49,2,51,9,13,20,25,18,13,9,54,47,34,35,45,8,19,6,61,26,29,5,41,56,35,22,32,51,25,29,43,51,53,42,11,59,40,20,24,7,52,35,31,26,50,7,25,12,21,62,38,41,43,42,1,40,5,47,32,11,46,28,13,56,20,18,50,8,29,31,35,0,34,12,10,23,18,63,32,50,47,3,48,35,24,17,23,57,39,56,40,4,60,52,6,30,46,62,5,58,19,11,48,51,3,57,48,16,22,50,52,8,57,47,53,51,43,37,49,36,42,46,54,38,24,39,8,23,30,8,6,41,23,31,5,48,43,55,62,30,57,5,29,17,27,59,15,2,0,25,49,9,1,31,2,40,11,36,48,17,62,61,13,56,25,26,24,38,48,16,23,14,55,11,59,27,24,7,33,0,1,63,46,58,48,32,14,28,11,8,20,3,45,21,62,44,0,38,43,51,23,48,60,36,56,57,15,48,26,38,46,35,59,33,28,39,37,16,51,36,55,38,30,7,12,23,25,47,63,16,18,7,30,24,31,51,23,56,25,11,49,13,35,1,27,14,29,28,60,22,14,44,37,27,41,55,33,58,38,23,52,11,26,30,60,21,44,24,25,36,62,59,31,43,13,34,53,50,6,23,8,45,22,26,11,4,8,9,12,34,2,29,56,44,55,49,50,18,46,32,1,15,25,53,63,20,60,26,2,53,49,0,54,28,9,35,16,39,32,51,56,11,5,47,40,22,12,38,40,28,14,41,24,22,23,59,55,60,4,56,31,15,6,13,10,5,2,24,4,25,18,3,35,19,22,55,63,34,2,28,43,38,24,50,23,53,13,62,59,35,6,10,63,49,28,58,0,12,35,33,5,1,51,40,19,56,62,45,63,55,20,57,43,18,8,49,37,41,9,32,17,50,61,50,23,35,22,32,9,51,60,6,31,2,34,4,30,57,47,6,37,13,49,28,27,45,6,36,57,12,21,3,13,49,7,0,21,15,56,0,23,45,53,17,57,8,26,53,36,8,49,42,0,21,41,18,29,14,23,37,36,24,58,15,35,45,44,48,22,19,13,41,8,45,44,42,35,30,20,34,11,56,51,38,31,1,53,8,59,9,30,63,42,50,2,44,58,60,35,20,54,59,37,58,51,2,48,59,16,6,3,63,19,49,57,34,63,0,58,31,5,61,36,62,31,55,3,57,63,19,10,30,9,46,26,48,62,63,24,26,40,49,29,8,38,0,53,46,44,2,35,11,62,29,30,40,19,60,42,2,45,48,28,14,47,27,40,36,18,60,24,61,10,49,30,62,50,36,16,21,20,45,14,57,49,19,55,27,5,25,20,30,59,42,46,29,28,37,25,61,19,37,41,0,1,19,26,8,56,40,10,38,2,43,58,49,8,29,32,22,20,16,0,43,55,54,59,45,21,16,58,11,10,14,44,52,51,16,5,61,49,55,42,28,15,15,11,46,28,42,47,10,17,23,45,56,36,13,31,62,42,59,52,37,11,3,22,31,22,48,30,45,5,54,21,20,57,50,2,46,11,3,30,56,48,31,13,14,47,22,2,31,26,19,20,7,42,3,33,5,31,0,4,37,25,62,28,30,3,10,55,27,40,21,46,16,14,49,41,58,51,26,34,36,18,55,50,44,54,29,17,11,42,46,7,30,19,62,22,45,42,61,54,13,25,27,63,8,58,48,52,30,46,62,50,43,18,13,4,1,42,15,36,8,29,14,28,18,25,44,0,4,33,17,55,48,26,53,8,18,27,55,10,14,52,34,62,3,56,23,62,9,57,37,42,51,8,29,21,10,6,2,0,15,32,57,11,58,23,60,6,7,40,2,56,0,35,27,61,4,49,55,1,61,45,48,41,15,11,35,47,31,12,62,15,17,28,7,26,23,1,59,31,58,33,40,37,45,59,57,38,29,44,31,26,37,33,61,52,39,27,29,47,19,12,33,8,36,46,44,42,4,49,58,10,25,29,1,27,5,63,60,37,32,41,3,2,61,24,20,30,52,47,14,22,5,55,9,35,32,58,38,60,56,50,63,12,7,13,58,19,59,1,7,45,57,34,48,24,33,25,7,47,29,50,49,36,30,38,5,6,14,26,52,0,57,50,12,30,63,17,27,13,25,42,2,49,57,51,29,60,20,63,60,7,19,45,16,20,22,29,14,17,24,19,25,11,40,45,61,22,62,46,58,43,57,32,0,42,8,26,9,31,51,17,25,4,43,28,40,2,60,30,1,21,63,47,50,9,31,21,56,51,29,52,24,57,38,59,0,46,50,27,11,4,54,31,8,62,42,12,56,58,39,10,7,45,22,21,2,62,37,44,12,46,47,19,34,52,7,41,4,51,29,37,54,21,3,32,24,9,31,7,17,54,5,43,11,42,23,58,41,13,12,21,26,13,55,22,49,23,41,31,62,31,20,28,6,23,45,58,51,38,44,57,11,2,61,50,3,35,52,41,62,4,10,28,14,1,45,5,56,32,20,54,25,60,35,24,48,31,39,38,15,27,44,10,60,32,37,19,2,25,44,6,29,43,40,10,57,18,10,5,9,46,7,51,8,30,32,9,6,49,21,32,28,55,43,7,33,27,5,7,40,42,9,17,48,51,12,8,26,4,13,26,48,37,41,57,60,47,53,3,30,49,34,55,32,46,3,43,17,61,20,41,19,54,52,15,61,45,2,18,35,5,38,10,42,49,53,60,50,54,25,45,1,63,39,33,13,37,20,50,30,29,53,3,4,0,17,31,43,54,9,20,18,23,8,35,60,26,7,10,31,55,49,20,28,39,57,50,39,1,59,30,7,21,14,46,55,54,41,51,21,1,43,59,33,34,61,5,46,6,60,35,4,13,36,42,63,22,43,32,24,39,52,19,7,38,62,12,41,10,16,18,63,29,14,46,15,42,38,36,55,33,34,14,60,4,42,30,8,6,43,18,62,23,2,33,60,61,15,17,16,49,20,35,0,53,45,55,42,61,9,31,2,36,28,51,17,18,48,19,11,34,47,26,41};

    auto opts = torch::TensorOptions().dtype(torch::kInt);

    auto select_index_tensor = torch::from_blob(select_index1.data(),{block_num,head_num,select_len},at::TensorOptions().dtype(torch::kInt)).clone().to(at::kCUDA);
    // std::cout<<select_index_tensor<<std::endl;

    test_gemm_(reinterpret_cast<float*>(query.transpose(-2,-1).contiguous().data_ptr()),reinterpret_cast<float*>(key.data_ptr()),reinterpret_cast<float*>(value.data_ptr()),reinterpret_cast<float*>(out.data_ptr()),reinterpret_cast<int*>(select_index_tensor.data_ptr()),block_num,head_num,block_size,head_size);

    std::vector<std::vector<int>> select_index;
    generate_select_index(block_num,head_num,select_len,select_index,ivec);
    for(int i=0;i<64*12;i++)
        for(int j=0;j<11;j++){
            select_index[i][j] = select_index1[i*11+j];
        }

    torch::Tensor k_out = torch::zeros({0,query.sizes()[2],query.sizes()[3]}).to(at::kCPU);
    torch::Tensor v_out = torch::zeros({0,query.sizes()[2],query.sizes()[3]}).to(at::kCPU);
    // std::cout<<k_out.sizes()<<" "<<v_out.sizes()<<std::endl;

    
    // std::cout<<select_index.size()<<std::endl;
    select_K_and_V(block_num,head_num,select_index,key.to(at::kCPU),value.to(at::kCPU),k_out,v_out);
    // std::cout<<k_out.sizes()<<" "<<v_out.sizes()<<std::endl;
    k_out = k_out.reshape({block_num,head_num,-1,d_num/head_num}).to(at::kCUDA);
    v_out = v_out.reshape({block_num,head_num,-1,d_num/head_num}).to(at::kCUDA);
    // std::cout<<k_out.sizes()<<" "<<v_out.sizes()<<std::endl;
    

    // auto q = ;
    query = query.to(at::kCUDA);

    torch::Tensor out1 = torch::bmm(query.reshape({block_num*head_num,block_size,d_num/head_num}),k_out.reshape({block_num*head_num,-1,block_size}).transpose(-2,-1));
    // std::cout<<out1.index({torch::indexing::Slice(241, 242),torch::indexing::Slice(0, 1)})<<std::endl;
    // std::cout<<query.reshape({block_num*head_num,block_size,d_num/head_num}).index({torch::indexing::Slice(0, 1),torch::indexing::Slice(0, 1),"..."})<<std::endl;
    // std::cout<<k_out.reshape({block_num*head_num,-1,block_size}).transpose(-2,-1).index({torch::indexing::Slice(0, 1),"...",torch::indexing::Slice(0, 1)})<<std::endl;


    auto max_value = std::get<0>(torch::max(out1,-1)).unsqueeze(-1);
    // std::cout<<max_value.index({torch::indexing::Slice(0, 1),"...",torch::indexing::Slice(0, 1)})<<std::endl;

    // std::cout<<max_value.sizes()<<std::endl;
    // // // std::cout<<max_value<<std::endl;
    // std::cout<<out1.index({torch::indexing::Slice(718, 719),torch::indexing::Slice(0, 1),"..."})<<std::endl;
    // std::cout<<out1[718][0][0]<<std::endl;
    auto attn_weights = torch::exp(out1 - max_value);
    // // auto attn_weights = torch::exp(out1 - max_value);

    auto sum_weight = attn_weights.sum(-1);
    // std::cout<<sum_weight.unsqueeze(-1).sizes()<<std::endl;
    // std::cout<<attn_weights.sizes()<<" "<<v_out.sizes()<<std::endl;

    torch::Tensor out2 = torch::bmm(attn_weights,v_out.reshape({block_num*head_num,-1,d_num/head_num}));
    std::cout<<sum_weight.index({torch::indexing::Slice(0, 1),"..."})<<std::endl;
    std::cout<<out2[0][0][0]<<" "<<sum_weight[0][0]<<std::endl;

    out2 = out2/sum_weight.unsqueeze(-1);
    // std::cout<<out2.sizes()<<std::endl;
    // std::cout<<out2[0][8]<<std::endl;
    // std::cout<<sum_weight[0]<<std::endl;
    // out2 = out2/sum_weight.unsqueeze(1);
    // std::cout<<out1.index({torch::indexing::Slice(0, 1),"..."})<<std::endl;
    // std::cout<<key.index({"...",torch::indexing::Slice(128,129)})<<std::endl;
    // std::cout<<out2.index({torch::indexing::Slice(0, 64),torch::indexing::Slice(0, 64)})<<std::endl;
    // print_tensor(reinterpret_cast<float*>(out2.to(at::kCPU).data_ptr()),64,64);
    // std::cout<<out1.index({torch::indexing::Slice(0, 1),torch::indexing::Slice(0, 1)})<<std::endl;

    // std::cout<<out[0][0]<<" "<<out<<std::endl;

    
    std::cout<<"The result is "<<check_value<float>(reinterpret_cast<float*>(out.to(at::kCPU).data_ptr()),reinterpret_cast<float*>(out2.to(at::kCPU).data_ptr()),out.numel(),out2.numel())<<std::endl;

}


void test_add_bias_and_transpose_(){
    int seq_len = 4096, d_num = 768;
    torch::Tensor input_data = torch::zeros({seq_len,d_num*3},torch::kFloat);
    torch::Tensor key =torch::zeros({seq_len,d_num},torch::kFloat).to(at::kCUDA);
    torch::Tensor value =torch::zeros({seq_len,d_num},torch::kFloat).to(at::kCUDA);
    torch::Tensor query =torch::zeros({seq_len,d_num},torch::kFloat).to(at::kCUDA);
    torch::Tensor bias = torch::zeros({d_num*3},torch::kFloat);

    generate_array(reinterpret_cast<float*>(input_data.data_ptr()),seq_len*d_num*3);
    generate_array(reinterpret_cast<float*>(bias.data_ptr()),3*d_num);

    int block_size = 64,head_num =12;
    int block_num = seq_len/block_size;
    int head_size = d_num / head_num;

    test_add_bias_and_transpose(reinterpret_cast<float*>(bias.to(at::kCUDA).data_ptr()),reinterpret_cast<float*>(input_data.to(at::kCUDA).data_ptr()),reinterpret_cast<float*>(query.data_ptr()),reinterpret_cast<float*>(key.data_ptr()),reinterpret_cast<float*>(value.data_ptr()),0,d_num,d_num*2,1,4096,12,64,64,64);

    input_data = input_data + bias;


    query = query.reshape({head_num,block_num,block_size,d_num/head_num});
    key = key.reshape({head_num,block_num,block_size,d_num/head_num});
    value = value.reshape({head_num,block_num,block_size,d_num/head_num});

    auto query_1 = input_data.index({"...",torch::indexing::Slice(0, d_num)}).reshape({block_num,block_size,head_num,head_size}).permute({2,0,1,3}).transpose(-2,-1).contiguous();
    auto key_1 = input_data.index({"...",torch::indexing::Slice(d_num, d_num*2)}).reshape({block_num,block_size,head_num,head_size}).permute({2,0,1,3}).contiguous();
    auto value_1 = input_data.index({"...",torch::indexing::Slice(d_num*2, d_num*3)}).reshape({block_num,block_size,head_num,head_size}).permute({2,0,1,3}).contiguous();

    std::cout<<"The result is "<<check_value<float>(reinterpret_cast<float*>(query_1.to(at::kCPU).data_ptr()),reinterpret_cast<float*>(query.to(at::kCPU).data_ptr()),key_1.numel(),key.numel())<<std::endl;

}

void test_add_bias_and_layernorm_(){
    int seq_len = 4096, d_num = 768;
    torch::Tensor input_data =torch::zeros({seq_len,d_num},torch::kFloat);
    torch::Tensor out_data =torch::zeros({seq_len,d_num},torch::kFloat).to(torch::kCUDA);
    torch::Tensor bias = torch::zeros({d_num},torch::kFloat);
    torch::Tensor layernorm_weight = torch::ones({d_num},torch::kFloat).to(torch::kCUDA);
    torch::Tensor layernorm_bias = torch::zeros({d_num},torch::kFloat).to(torch::kCUDA);

    generate_array(reinterpret_cast<float*>(input_data.data_ptr()),seq_len*d_num);
    generate_array(reinterpret_cast<float*>(bias.data_ptr()),d_num);
    

    input_data = input_data.to(torch::kCUDA);
    bias = bias.to(torch::kCUDA);

    test_add_bias_and_layernorm(reinterpret_cast<float*>(out_data.data_ptr()),reinterpret_cast<float*>(input_data.data_ptr()),reinterpret_cast<float*>(bias.data_ptr()),4096,2,768,float(1e-5),reinterpret_cast<float*>(layernorm_weight.data_ptr()),reinterpret_cast<float*>(layernorm_bias.data_ptr()));

    input_data += bias;
    torch::nn::LayerNorm model(torch::nn::LayerNormOptions({768}).elementwise_affine(false).eps(1e-5));
    input_data = model(input_data);

    
    std::cout.flags(std::ios::fixed);
    std::cout.precision(6);
    float a = 1.1f;
    // std::cout<<a<<std::endl;
    
    std::cout<<reinterpret_cast<float*>(torch::mean(input_data.to(at::kCPU),1).data_ptr())[0]<<" "<<reinterpret_cast<float*>(torch::mean(input_data.to(at::kCPU),1).data_ptr())[1]<<" "<<reinterpret_cast<float*>(torch::var(input_data.to(at::kCPU)[0],false).data_ptr())[0]<<" "<<reinterpret_cast<float*>(torch::var(input_data.to(at::kCPU)[1], false).data_ptr())[0]<<" "<<std::endl;

    // std::cout<<out_data<<std::endl;
    
    std::cout<<"The result is "<<check_value<float>(reinterpret_cast<float*>(input_data.to(at::kCPU).data_ptr()),reinterpret_cast<float*>(out_data.to(at::kCPU).data_ptr()),input_data.numel(),out_data.numel())<<std::endl;

}

void test_mat_mul(){
    int seq_len = 4096, d_num = 768;
    torch::Tensor A =torch::zeros({seq_len,d_num},torch::kFloat);
    torch::Tensor B =torch::zeros({d_num,3*d_num},torch::kFloat);
    torch::Tensor out_data =torch::zeros({seq_len,3*d_num},torch::kFloat).to(torch::kCUDA);
    generate_array(reinterpret_cast<float*>(A.data_ptr()),seq_len*d_num);
    generate_array(reinterpret_cast<float*>(B.data_ptr()),d_num);

    A = A.to(torch::kCUDA);
    B = B.to(torch::kCUDA);

    sparse_transformers::layers::kernels::MatMul(A,false,B,false,1,out_data,0);

    auto out2 = torch::matmul(A,B);

    std::cout<<"The result is "<<check_value<float>(reinterpret_cast<float*>(out_data.to(at::kCPU).data_ptr()),reinterpret_cast<float*>(out_data.to(at::kCPU).data_ptr()),out2.numel(),out_data.numel())<<std::endl;
}

int main()
{
    test_mat_mul();
    return 0;
}
}
}
}